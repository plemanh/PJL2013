# import glob
#permet d'acceder a une liste des fichiers python
# t=glob.glob('./*.py') t[0] donne le premier fichier python


import glob
import sklearn
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer

cv=CountVectorizer()

Z=[file('/Users/Louis/Desktop/PJL2013/donnee/testdonne.txt').read(),file('/Users/Louis/Desktop/PJL2013/donnee/testdonne1.txt').read()]

X=cv.fit_transform(Z)


tf=TfidfTransformer(use_idf=False).fit(X)

Y=tf.transform(X)


# Test countvectorizer sur plusieurs fichiers:
fichiers=glob.glob('/Users/Louis/Desktop/PJL2013/donnee/*.txt')
sumdata=[]

# pour mettre tous les textes dans un seul
# fonctionne
for x in fichiers:
	sumdata.append(file(x).read())
pass


X1=cv.fit_transform(sumdata)

#X1=cv.fit_transform(sumdonne)
